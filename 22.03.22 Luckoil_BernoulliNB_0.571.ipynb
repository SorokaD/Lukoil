{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72eabb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import itertools\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddd99a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция удаления нулевых столбцов\n",
    "def del_zero (data):\n",
    "    zero_value=[]\n",
    "    for i in range(1,261):\n",
    "        if data.iloc[:,i].sum()==0: zero_value.append(data.iloc[:,i].name)\n",
    "    print('Пустые столбцы ',zero_value, ' удалены')\n",
    "    data=data.drop(zero_value, axis=1)\n",
    "    return data\n",
    "    \n",
    "# функция удаления  признаков с пропущенными значениями число которых больше порога a_del\n",
    "def del_na(data, a_del):\n",
    "    na_values=pd.DataFrame(columns=[['null_sum','null_in_0','null_in_1', 'null_in_2']])\n",
    "    for i in range(0,data.shape[1]):\n",
    "        temp=[]\n",
    "        if data.iloc[:,i].isnull().sum()>a_del:\n",
    "            temp.append(data.iloc[:,i].isnull().sum())\n",
    "            temp.append(data.query('TARGET==0').iloc[:,i].isnull().sum())\n",
    "            temp.append(data.query('TARGET==1').iloc[:,i].isnull().sum())\n",
    "            temp.append(data.query('TARGET==2').iloc[:,i].isnull().sum())\n",
    "            nm=data.iloc[:,i].name\n",
    "            na_values.loc[nm]=temp\n",
    "    data=data.drop(list(na_values.index), axis=1)\n",
    "    print(' Признаки с количеством порпусков >',a_del, '\\n', na_values, ' удалены')\n",
    "    return(data)\n",
    "\n",
    "# удалим признаки в которых есть сильный дисбаланс, одно из значений подавляющее (больше порога max_count)\n",
    "# из далее построенных гистограм, был сделан вывод что интересным может показаться порог отсечения _______\n",
    "def del_disbal(data, max_count):\n",
    "    disbal_values=pd.DataFrame(columns=[['max_sum','max_in_0','max_in_1','max_in_2']])\n",
    "    for i in range(0,data.shape[1]):\n",
    "        temp=[]\n",
    "        if data.iloc[:,i].value_counts().max()>max_count:\n",
    "            temp.append(data.iloc[:,i].value_counts().max())\n",
    "            temp.append(data.query('TARGET==0').iloc[:,i].value_counts().max())\n",
    "            temp.append(data.query('TARGET==1').iloc[:,i].value_counts().max())\n",
    "            temp.append(data.query('TARGET==2').iloc[:,i].value_counts().max()) \n",
    "            nm=data.iloc[:,i].name\n",
    "            disbal_values.loc[nm]=temp\n",
    "    data=data.drop(list(disbal_values.index), axis=1)\n",
    "    print(' Признаки с дисбалансом >',max_count, '\\n', disbal_values, ' удалены')\n",
    "    return(data)\n",
    "\n",
    "def del_high_corr(data, cut_off=0.7):\n",
    "    \n",
    "    \"\"\"\n",
    "    Функция предназначена для удаления признаков, у которых корреляция выше некоторого порога.\n",
    "    Функция принимает следующие параметры:\n",
    "    data: pandas.DataFrame - данные, для которых будет рассчитана матрица корреляций;\n",
    "    cut_off: float - порог отсечения коррелирующих признаков, значение по умолчанию равно 0.7,\n",
    "    что в соответствии с таблицей Чеддока соответствует высокой силе корреляционной связи.\n",
    "    Функция ничего не возвращает, она удаляет признаки, корреляция которых превышает установленный\n",
    "    порог.\n",
    "    \"\"\"\n",
    "    \n",
    "    i, to_drop = 0, []\n",
    "    while True:\n",
    "        corr_ = data.corr(method='spearman') >= cut_off\n",
    "        tmp = list(zip(corr_.sum().index, corr_.sum()))\n",
    "        if tmp[i][1] > 1:\n",
    "            data.drop(tmp[i][0], axis=1, inplace=True)\n",
    "            print(f'Признак {tmp[i][0]} был удалён')\n",
    "        else:\n",
    "            i +=1\n",
    "        if data.shape[1] == corr_.sum().values.sum():\n",
    "            break\n",
    "\n",
    "# опишем функцию заполнения пропущенных значений\n",
    "def imputer(data, n_n):\n",
    "    imp = KNNImputer(n_neighbors=n_n, weights=\"uniform\")\n",
    "    not_nan_mass=imp.fit_transform(data)\n",
    "    ft_list=list(data.columns)\n",
    "    data_not_nan=pd.DataFrame(not_nan_mass, columns=ft_list)\n",
    "    return(data_not_nan)\n",
    "\n",
    "# ВСПОМОГАТЕЛЬНАЯ ФУНКЦИЯ посмотрим на признаки с пропущенными значениями и их представленность в каждом классе\n",
    "def na_val(data):\n",
    "    na_values=pd.DataFrame(columns=[['null_sum','null_in_0','null_in_1', 'null_in_2']])\n",
    "    for i in range(0,data.shape[1]):\n",
    "        temp=[]\n",
    "        if data.iloc[:,i].isnull().sum()>0:\n",
    "            temp.append(data.iloc[:,i].isnull().sum())\n",
    "            temp.append(data.query('TARGET==0').iloc[:,i].isnull().sum())\n",
    "            temp.append(data.query('TARGET==1').iloc[:,i].isnull().sum())\n",
    "            temp.append(data.query('TARGET==2').iloc[:,i].isnull().sum())\n",
    "            nm=data.iloc[:,i].name\n",
    "            na_values.loc[nm]=temp\n",
    "    return(na_values)\n",
    "    \n",
    "# опишем функцию коррекции заполненных категориальных значений\n",
    "def corr_cat(data, num_cat):\n",
    "    ft_list=list(na_val(data).index)\n",
    "    lst_count=pd.DataFrame(columns=[['feature_count_values']])\n",
    "    for i in range (na_val(data).shape[0]):\n",
    "        if len(list(data[ft_list[i]].value_counts()))<= num_cat: \n",
    "            lst_count.loc[ft_list[i]]=len(list(data[ft_list[i]].value_counts()))\n",
    "    data[list(lst_count.index)].astype(float).round()\n",
    "    return(data)\n",
    "\n",
    "# модель добивания бедных классов 1\n",
    "def model_bal_1(X_train, y_train):\n",
    "    X_res, y_res = SMOTE().fit_resample(X_train, y_train)\n",
    "    return(X_res,y_res)\n",
    "\n",
    "# модель добивания бедных классов 2\n",
    "def model_bal_2(X_train, y_train):\n",
    "    X_res, y_res = ADASYN().fit_resample(X_train, y_train)\n",
    "    return(X_res,y_res)\n",
    "    \n",
    "# модель добивания бедных классов 3\n",
    "def model_bal_3(X_train, y_train):\n",
    "    X_res, y_res = BorderlineSMOTE().fit_resample(X_train, y_train)\n",
    "    return(X_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cdc1e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train: (18390, 262)\n",
      "Размер test: (6131, 261)\n",
      "0    13029\n",
      "1     4237\n",
      "2     1124\n",
      "Name: TARGET, dtype: int64\n",
      "Пустые столбцы  ['FEATURE_3', 'FEATURE_144', 'FEATURE_249', 'FEATURE_256']  удалены\n",
      " Признаки с количеством порпусков > 3000 \n",
      "             null_sum null_in_0 null_in_1 null_in_2\n",
      "FEATURE_187     8857      6502      1849       506\n",
      "FEATURE_189    18146     12854      4178      1114\n",
      "FEATURE_190    12889      9201      2826       862\n",
      "FEATURE_191    11451      8307      2423       721\n",
      "FEATURE_192     9752      7040      2081       631\n",
      "FEATURE_193     9382      6823      1977       582\n",
      "FEATURE_194    12952      9081      2994       877  удалены\n",
      " Признаки с дисбалансом > 18000 \n",
      "             max_sum max_in_0 max_in_1 max_in_2\n",
      "FEATURE_5     18386    13026     4236     1124\n",
      "FEATURE_6     18172    12877     4185     1110\n",
      "FEATURE_20    18349    13003     4225     1121\n",
      "FEATURE_27    18358    13004     4231     1123\n",
      "FEATURE_28    18364    13010     4231     1123\n",
      "FEATURE_29    18363    13013     4229     1121\n",
      "FEATURE_30    18365    13011     4232     1122\n",
      "FEATURE_31    18378    13024     4231     1123\n",
      "FEATURE_32    18377    13021     4234     1122\n",
      "FEATURE_75    18337    13008     4225     1104\n",
      "FEATURE_139   18235    12946     4178     1111\n",
      "FEATURE_140   18308    12972     4217     1119\n",
      "FEATURE_141   18308    12972     4217     1119\n",
      "FEATURE_146   18097    12822     4160     1115\n",
      "FEATURE_156   18185    12908     4166     1111\n",
      "FEATURE_157   18015    12790     4134     1091\n",
      "FEATURE_159   18388    13028     4236     1124\n",
      "FEATURE_229   18349    13003     4225     1121  удалены\n"
     ]
    }
   ],
   "source": [
    "# читаем данные\n",
    "train=pd.read_csv('contest_train.csv')\n",
    "test=pd.read_csv('contest_test.csv')\n",
    "# выводим важные параметры\n",
    "print('Размер train:', train.shape)\n",
    "print('Размер test:', test.shape)\n",
    "print(train.TARGET.value_counts())\n",
    "# удаляем нулевые/пустые столбцы\n",
    "train=del_zero(train)\n",
    "# удаляем все признаки в которых больше ХХХ пустых значений\n",
    "train=del_na(train, 3000) # 3\n",
    "# удаляем все признаки в которых есть дисбаланс, одно из значений сильно подавляющее\n",
    "train=del_disbal(train, 18000) # 18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267721f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполним порпущенные значения \n",
    "train=imputer(train,3)\n",
    "# скорректируем заполненные категориальные значения\n",
    "train=corr_cat(train, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843bf3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.iloc[:,1:-1]\n",
    "y=train.TARGET\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=0)\n",
    "target_names = ['class 0', 'class 1', 'class 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ff31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = model_bal_3(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdd618a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.54      0.58      0.56      3840\n",
      "     class 1       0.51      0.42      0.46      3840\n",
      "     class 2       0.66      0.72      0.69      3840\n",
      "\n",
      "    accuracy                           0.58     11520\n",
      "   macro avg       0.57      0.58      0.57     11520\n",
      "weighted avg       0.57      0.58      0.57     11520\n",
      "\n",
      "Fmacro мера: 0.5717210417485245\n"
     ]
    }
   ],
   "source": [
    "clf = BernoulliNB(alpha = 1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred=clf.predict(X_test)\n",
    "print(classification_report(y_test, pred, target_names=target_names))\n",
    "print('Fmacro мера:',f1_score(y_test, pred, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
